<ul class="publications">
    <li class="bibliography">
        <div class="title">
            <a href="https://aclanthology.org/2022.findings-acl.55/">Mitigating Gender Bias in Distilled Language Models via Counterfactual Role Reversal</a>
        </div>
        <div class="details">
            <div class="authors">
                <div class="highlight">Umang Gupta</div>, Jwala Dhamala, Varun Kumar, Apurv Verma, Yada Pruksachatkun, Satyapriya Krishna, Rahul Gupta, Kai-Wei Chang, Greg Ver Steeg, Aram Galstyan
            </div>
            <div class="venue_year">Findings of the Association for Computational Linguistics (ACL 2022)</div>
            <p class="note">
                We mitigate gender disparity in text generation while performing knowledge distillation by exploiting counterfactual role-reversed texts for training. 
            </p>
        </div>
    </li>

    <li class="bibliography">
        <div class="title">
            <a href="https://openreview.net/forum?id=8lL_y9n-CV">Membership Inference Attacks on Deep Regression Models for Neuroimaging
            </a>
        </div>
        <div class='details'>
            <div class="authors">
                <div class="highlight">Umang Gupta</div>, Dimitris Stripelis, Pradeep K. Lam, Paul Thompson, Jose Luis Ambite, Greg Ver Steeg
            </div>
            <div class="venue_year">Medical Imaging and Deep Learning (2021)</div>
            <!-- <details>
                <summary> Summary </summary> -->
                <p class='note'>
                    We illustrate that allowing access to model parameters can leak private information about the training set. We observed strong correlations between privacy leakage and overfitting, indicating that reducing overfitting may ensure privacy.
                    <!-- We illustrate that allowing access to model parameters may leak private information about the dataset. In particular, we show that it is possible to infer if a sample was part of the training set used to train the model given only access to the model prediction (black-box) or access to the model itself (white-box) and some leaked samples from the training data distribution. Such attacks are commonly referred to as Membership Inference attacks. We show realistic Membership Inference attacks on deep learning models trained for brain age prediction in a centralized and decentralized setup. We further observed strong correlations between membership inference attack success and overfitting, an indication that we may be able to ensure privacy and prevent these attacks by reducing overfitting. -->
                </p>
            <!-- </details> -->
        </div>
    </li>

    <li class="bibliography">
        <div class="title">
            <a href="https://arxiv.org/abs/2101.04108"> Controllable Guarantees for Fair Outcomes via Contrastive Information Estimation </a>
        </div>
        <div class='details'>
            <div class="authors">
                <div class="highlight">Umang Gupta</div>, Aaron Ferber, Bistra Dilkina, Greg Ver Steeg
            </div>
            <div class="venue_year">The Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21)</div>
            <!-- <details> -->
                <!-- <summary> Summary </summary> -->
                <p class='note'>
                    We show that limiting the mutual information between the representations limits any classifier's statistical parity. To this end, we propose a novel method for controlling fairness through mutual information based on contrastive information estimators.
                    <!-- We propose a new representation learning algorithm to control parity of any decision algorithm. We theoretically establish that by limiting the mutual information between representations and protected attributes, we can assuredly limit the statistical parity of any classifier. We demonstrate an effective method for controlling fairness through mutual information based on contrastive information estimators and show that they outperform approaches that rely on variational bounds based on complex generative models. -->
                </p>
            <!-- </details> -->
            <ul>
                <li class="video"><a href="https://youtu.be/f_paYisG3yo">video</a></li>
                <li class="code"><a href="https://github.com/umgupta/fairness-via-contrastive-estimation">code</a></li>
            </ul>
        </div>
    </li>

    <li class="bibliography">
        <div class="title">
            <a href="https://arxiv.org/2102.04438">Improved Brain Age Estimation with Slice-based Set Networks</a>
        </div>
        <div class='details'>
            <div class="authors">
                <div class="highlight">Umang Gupta</div>, Pradeep K. Lam, Greg Ver Steeg, Paul M. Thompson
            </div>
            <div class="venue_year">18th International Symposium on Biomedical Imaging (ISBI-21)</div>
            <!-- <details>
                <summary> Summary </summary> -->
                <p class='note'>
                    <!-- We propose a new architecture for BrainAGE prediction, which works by encoding a single 2D slice in an MRI with a deep 2D-CNN model and combining the information from these 2D-slice encodings by using set networks or permutation invariant lay- ers. Experiments on the BrainAGE prediction problem, using the UK Biobank dataset showed that the model with the permutation invariant layers trains faster and provides better predictions compared to the other state-of-the-art approaches. -->
                    We propose a new architecture for making predictions over 3D-MRIs prediction, which works by encoding a single 2D slice in an MRI with a deep 2D-CNN model and integrating the information from these 2D-slice encodings with permutation invariant layers. 
                </p>
            <ul>
            <!-- </details> -->
                <li class="code"><a href="https://github.com/umgupta/2d-slice-set-networks-for-brain-age">code</a></li>
            </ul>
        </div>
    </li>

    <li class="bibliography">
        <div class="title">
            <a href="https://link.springer.com/chapter/10.1007%2F978-3-030-32430-8_15"> DeepFP for Finding Nash Equilibrium in Continuous Action Spaces </a>
        </div>
        <div class='details'>
            <div class="authors">
                Nitin Kamra, <div class="highlight">Umang Gupta</div>, Kai Wang, Fei Fang, Yan Liu, Milind Tambe
            </div>
            <div class="venue_year">Decision and Game Theory for Security (GameSec 2019)</div>
            <p class='note'>
                We propose an approximate extension of fictitious play in continuous action spaces by modeling best responses with implicit density models. 
                    <!-- An approximate extension of fictitious play in continuous action spaces, DeepFP is proposed. DeepFP represents players’ approximate best responses with implicit density approximators and trains them with a model-based learning regime. We demonstrate stable convergence to Nash equilibrium on several classic games and in a forest security domain. DeepFP learns strategies robust to adversarial exploitation and scales well with players’ resources. -->
            </p>
            <!-- </details> -->
        </div>
    </li>

    <li class="bibliography">
        <div class="title">
            <a href="https://arxiv.org/abs/1710.10368">Deep Generative Dual Memory Network for Continual Learning</a>
        </div>
        <div class='details'>
            <div class="authors">
                Nitin Kamra, <div class="highlight">Umang Gupta</div>, Yan Liu
            </div>
            <div class="venue_year">arXiv:1710.10368</div>
                <!-- <li class="arxiv"></li> 
            </ul>
            <details>
                <summary> Summary </summary> -->
            <p class='note'>
                Deriving inspiration from human complementary learning systems (hippocampus and neocortex), we develop a dual generative memory architecture that consolidates memory via generative replay and is capable of learning continuously from sequentially incoming tasks while averting catastrophic forgetting. 
                <!-- Deriving inspiration from human complementary learning systems (hippocampus and neocortex), we develop a dual memory architecture capable of learning continuously from sequentially incoming tasks while averting catastrophic forgetting. We perform memory consolidation via generative replay of past experiences and demonstrate improved retention on task of learning from sequential non-iid examples. -->
            </p>
            <!-- </details> -->
        </div>
    </li>
</ul>

